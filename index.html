
<html>
<head>
	<meta content="text/html; charset=utf-8" http-equiv="Content-Type" />
	<title>Kang Yang</title>
	<meta content="kang Yang, kang Yang.github.io" name="keywords" />
	<style media="screen" type="text/css">html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, font, img, ins, kbd, q, s, samp, small, strike, strong, sub, tt, var, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td {
  border: 0pt none;
  font-family: inherit;
  font-size: 100%;
  font-style: inherit;
  font-weight: inherit;
  margin: 0pt;
  outline-color: invert;
  outline-style: none;
  outline-width: 0pt;
  padding: 0pt;
  vertical-align: baseline;
}
a {
  color: #1772d0;
  text-decoration:none;
}
a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
}
a.paper {
  font-weight: bold;
  font-size: 14pt;
}
b.paper {
  font-weight: bold;
  font-size: 14pt;
}
* {
  margin: 0pt;
  padding: 0pt;
}
body {
  position: relative;
  margin: 3em auto 2em auto;
  width: 1000px;
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 16px;
  background: #eee;
}
h2 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 17pt;
  font-weight: 700;
}
h3 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 18px;
  font-weight: 700;
}
strong {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 15px;
  font-weight:bold;
}
ul { 
  list-style: circle;
}
img {
  border: none;
}
li {
  padding-bottom: 0.5em;
  margin-left: 1.4em;
}
alert {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 15px;
  font-weight: bold;
  color: #FF0000;
}
em, i {
	font-style:italic;
}
div.section {
  clear: both;
  margin-bottom: 1.5em;
  background: #eee;
}
div.spanner {
  clear: both;
}
div.paper {
  clear: both;
  margin-top: 0.5em;
  margin-bottom: 1em;
  border: 1px solid #ddd;
  background: #fff;
  padding: 1em 1em 1em 1em;
}
div.paper div {
  padding-left: 230px;
}
img.paper {
  margin-bottom: 0.5em;
  float: left;
  width: 200px;
}
span.blurb {
  font-style:italic;
  display:block;
  margin-top:0.75em;
  margin-bottom:0.5em;
}
pre, code {
  font-family: 'Lucida Console', 'Andale Mono', 'Courier', monospaced;
  margin: 1em 0;
  padding: 0;
}
div.paper pre {
  font-size: 0.9em;
}
</style>

<link href="http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css" /><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans+Condensed:300' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz' rel='stylesheet' type='text/css'>-->
</head>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-45959174-3', 'kangyang.github.io');
  ga('send', 'pageview');
</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-66888300-1', 'auto');
  ga('send', 'pageview');
</script>
<body>
<div style="margin-bottom: 1em; border: 1px solid #ddd; background-color: #fff; padding: 1em; height: 140px;">
<div style="margin: 0px auto; width: 100%;">
<img title="Tonghe" style="float: left; padding-left: .01em; height: 140px;" src="kang.jpg" />
<div style="padding-left: 12em; vertical-align: top; height: 120px;"><span style="line-height: 150%; font-size: 20pt;">Kang Yang</span><br />
<span><strong>PhD Student</strong></span><br />
<!--<span><a href='http://cvrs.whu.edu.cn/'>Computer Vision & Remote Sensing (CVRS) Lab </a> <br /> </q>-->
<span>Electrical Engineering and Computer Science Department, UC Merced.</span><br />
<span><strong>Office</strong>: 230V, Science and Engineering Building 2, UC Merced, CA 95343</span><br />
<span><strong>Email  </strong>: kyang73 [at] ucmerced [dot] edu  &nbsp &nbsp  
<strong><a href='https://github.com/kangyang73'>Github</a></strong>  &nbsp &nbsp
<strong><a href='https://scholar.google.com/citations?user=SJXhytMAAAAJ&hl=en&oi=ao'>Google Scholar</a></strong></span><br/>
<!-- <span><strong> <a href='https://github.com/kailigo'>Github</a> </strong></span> <br /> -->
<!-- <span><strong> <a href='https://scholar.google.com/citations?hl=en&user=YsROc4UAAAAJ'>Google Scholar</a> </strong></span> <br /> -->
</div>
</div>
</div>
<!--<div style="clear: both; background-color: #fff; margin-top: 1.5em; padding: .2em; padding-left: .3em;">-->

<div style="clear: both;">
<div class="section">
<h2>About Me</h2>
<div class="paper">
I am a third-year Ph.D. student in the Department of Electrical Science and Computer Engineering,  advised by Prof. Wan Du. 
<!--I was a research intern from June, 2018 to August, 2018 at Tencent AI Lab. -->
My research interest includes the Internet of Things and wireless and mobile networking. For more information, please see my  
<a href='https://1drv.ms/b/s!AquxeCnmoev-i9xCCN0g7FUkq1YDLw?e=KRo5xu'>CV</a>.
</div>
</div>
</div>


<div style="clear: both;">
<div class="section">
  <h2>News</h2>
  <div class="paper">
    <ul>
  <!-- <li> 2020.02: Two papers are accepted by CVPR 2020.</li>    
  <li> 2019.08: One paper is accepted by CIKM 2019.</li>
  <li> 2019.07: Three papers are accepted by ICCV 2019.</li>     
  <li> 2018.12: One paper is accepted by ICLR 2019.</li>       
  <li> 2018.09: One paper is accepted by TNNLS.</li>   
  <li> 2018.07: One paper is accepted by ACM MM 2018 as full long paper.</li>   
  <li> 2018.07: One paper is accepted by ECCV 2018.</li>    
  <li> 2018.06: Invited to serve as the committee member of AAAI 2019.</li>
	<li> 2017.11: Two papers are accepted by AAAI18.</li>    -->
	<li> 2018.08: Begin my new study journey in UC Merced.</li>   
    </ul>
  </div>
</div>
</div>




<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Publications</h2>
<div class="paper">

<h4 id="confpapers">Conference</h4>
<ul>

<li> <u>Tiantian Wang</u>, Sifei Liu, Kai Li, Yapeng Tian, Ming-Hsuan Yang.
<i> Video Matting via Consistency-Regularized Graph Neural Networks. </i> 
International Conference on Computer Vision </i> (<strong>ICCV</strong>), 2021. [PDF][code]
</li>

<!-- <div> <strong>Video Matting via Consistency-Regularized Graph Neural Networks</strong><br>
<strong><u>Tiantian Wang</u></strong>, Sifei Liu, Kai Li, Yapeng Tian, Ming-Hsuan Yang<br>
International Conference on Computer Vision (<strong>ICCV</strong>), 2021
[PDF][Code]
</div>
<div class="spanner"></div>
</div>
-->

<li> <u>Tiantian Wang</u>, Yongri Piao, Xiao Li, Lihe Zhang, Huchuan Lu.
<i> Deep Learning for Light Field Saliency Detection. </i> 
International Conference on Computer Vision </i> (<strong>ICCV</strong>), 2019. [PDF][code]
</li>

<!-- <div> <strong>Deep Learning for Light Field Saliency Detection</strong><br>
<strong><u>Tiantian Wang</u></strong>, Yongri Piao, Xiao Li, Lihe Zhang, Huchuan Lu<br>
International Conference on Computer Vision (<strong>ICCV</strong>), 2019
[PDF][Code]
</div>
<div class="spanner"></div>
</div>
-->

<li> Yi-Wen Chen, Yi-Hsuan Tsai, <u>Tiantian Wang</u>, Yen-Yu Lin, Ming-Hsuan Yang.
<i> Referring Expression Object Segmentation with Caption-Aware Consistency. </i> 
British Machine Vision Conference </i> (<strong>BMVC</strong>), 2019. [PDF][code]
</li>

<!-- <div> <strong>Referring Expression Object Segmentation with Caption-Aware Consistency</strong><br>    
Yi-Wen Chen, Yi-Hsuan Tsai, <strong><u>Tiantian Wang</u></strong>, Yen-Yu Lin, Ming-Hsuan Yang<br>
British Machine Vision Conference  (<strong>BMVC</strong>), 2019 
[PDF][Code]
</div>
<div class="spanner"></div>
</div>
 -->

<!-- <div class="paper" id="AttnBN"><img class="paper" src="./pic/AttnBN.png" title="Attention Bridging Network for Knowledge Transfer"> -->

<li> <u>Tiantian Wang</u>, Lihe Zhang, Shuo Wang, Huchuan Lu, Gang Yang, Xiang Ruan, Ali Borji.
<i> Detect Globally, Refine Locally: A Novel Approach to Saliency Detection. </i> 
IEEE Computer Society Conference on Computer Vision and Pattern Recognition </i> (<strong>CVPR</strong>), 2018. [PDF] [<a href='https://github.com/TiantianWang/CVPR18_detect_globally_refine_locally.git'>code</a>]
</li>

<!-- <div> <strong>Detect Globally, Refine Locally: A Novel Approach to Saliency Detection</strong><br>    
<strong><u>Tiantian Wang</u></strong>, Lihe Zhang, Shuo Wang, Huchuan Lu, Gang Yang, Xiang Ruan, Ali Borji <br>
IEEE Computer Society Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2018
[PDF][Code]
</div>
<div class="spanner"></div>
</div>
-->

<li> Xiaoning Zhang<strong>*</strong>, <u>Tiantian Wang</u><strong>*</strong>, Lihe Zhang, Shuo Wang, Huchuan Lu, Gang Yang, Xiang Ruan, Ali Borji.
<i> Progressive Attention Guided Recurrent Network for Salient Object Detection. </i> 
IEEE Computer Society Conference on Computer Vision and Pattern Recognition </i> (<strong>CVPR</strong>), 2018. [PDF][code] (<strong>*</strong> denotes equal contribution)
</li>


<!-- <div class="paper" id="RNAN"><img class="paper" src="./pic/RNAN.png" title="Residual Non-local Attention Networks for Image Restoration">
<div> <strong>Progressive Attention Guided Recurrent Network for Salient Object Detection</strong><br>
Xiaoning Zhang<strong>*</strong>, <strong>Tiantian Wang*</strong>, Jinqing Qi, Huchuan Lu, Gang Wang <strong>*</strong> denotes equal contributions <br> 
IEEE Computer Society Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2018
[PDF][Code]
</div>
<div class="spanner"></div>
</div> -->

<li> <u>Tiantian Wang</u>, Ali Borji, Lihe Zhang, Pingping Zhang, Huchuan Lu.
<i> A Stagewise Refinement Model for Detecting Salient Objects in Images. </i> 
International Conference on Computer Vision </i> (<strong>ICCV</strong>), 2017. [PDF]
[<a href='https://github.com/TiantianWang/ICCV17_SRM.git'>Code</a>]
</li>


<!-- <div class="paper" id="AttnBN"><img class="paper" src="./pic/AttnBN.png" title="Attention Bridging Network for Knowledge Transfer">
<div> <strong>A Stagewise Refinement Model for Detecting Salient Objects in Images</strong><br>    
<strong><u>Tiantian Wang</u></strong>, Ali Borji, Lihe Zhang, Pingping Zhang, Huchuan Lu <br>
International Conference on Computer Vision (<strong>ICCV</strong>), 2017
[PDF][Code]
</div>
<div class="spanner"></div>
</div>
-->

<!-- <li> Tiantian Wang, Ali Borji, Lihe Zhang, Pingping Zhang, Huchuan Lu.
<i> A Stagewise Refinement Model for Detecting Salient Objects in Images </i> 
International Conference on Computer Vision </i> (<strong>ICCV</strong>), 2017. [PDF][code]
</li>
 -->

<li> <u>Tiantian Wang</u>, Ali Borji, Lihe Zhang, Pingping Zhang, Huchuan Lu.
<i> Kernelized Subspace Ranking for Saliency Detection. </i> 
European Conference on Computer Vision </i> (<strong>ECCV</strong>), 2017. [PDF]
[<a href='https://github.com/TiantianWang/ECCV16_KSR.git'>Code</a>]
</li>

<!-- 
<li> Tiantian Wang, Ali Borji, Lihe Zhang, Pingping Zhang, Huchuan Lu.
<i> Kernelized Subspace Ranking for Saliency Detection. </i> 
International Conference on Computer Vision </i> (<strong>ICCV</strong>), 2017. [PDF][code]
</li>
 -->

<!-- <div class="paper" id="AttnBN"><img class="paper" src="./pic/AttnBN.png" title="Attention Bridging Network for Knowledge Transfer">
<div> <strong>Kernelized Subspace Ranking for Saliency Detection</strong><br>    
<strong><u>Tiantian Wang</u></strong>, Lihe Zhang, Huchuan Lu, Chong Sun, Jinqing Qi <br>
European Conference on Computer Vision (<strong>ECCV</strong>), 2016
[PDF][Code]
 -->

<!-- </div> -->
<!-- <div class="spanner"></div> -->
<!-- </div> -->

</ul> 


<h4 id="confpapers">Journal</h4>
  <ul>
<li> 
Lihe Zhang, Xiang Fang, Hongguang Bo, <u>Tiantian Wang</u>, Huchuan Lu 
<i> Deep Multi-Level Networks with Multi-Task Learning for Saliency Detection. </i> 
</i> (<strong>Neurocomputing</strong>), 2019. [PDF][code]
</li>



<li> 
Lihe Zhang, Xiang Fang, Hongguang Bo, <u>Tiantian Wang</u>, Huchuan Lu 
<i> Multi-scale Pyramid Pooling Network for Salient Object Detection. </i> 
</i> (<strong>Neurocomputing</strong>), 2018. [PDF][code]
</li>


<li> 
Dakhia Abdelhafid, <u>Tiantian Wang</u>, Huchuan Lu 
<i> A Hybrid-Backward Renement Model for Salient Object Detection. </i> 
</i> (<strong>Neurocomputing</strong>), 2018. [PDF][code]
</li>



<li> 
Wenlong Guan, <u>Tiantian Wang</u>, Jinqing Qi, Lihe Zhang, Huchuan Lu
<i> Edge-Aware Convolution Neural Network Based Salient Object Detection. </i> 
</i> (<strong>IEEE SPL</strong>), 2019. [PDF][code]
</li>


<li> 
<!-- Wenlong Guan, <u>Tiantian Wang</u>, Jinqing Qi, Lihe Zhang, Huchuan Lu -->
Lihe Zhang, Jie Wu, <u>Tiantian Wang</u>, Pingping Zhang, Ali Borji, Huchuan Lu
<i> A Multi-Stage Refinement Network for Salient Object Detection </i> 
</i> (<strong>IEEE TIP</strong>), 2019. [PDF][code]
</li>

</ul> 

  </div>
</div>
</div>

<!-- <div class="paper" id="AttnBN"><img class="paper" src="./pic/AttnBN.png" title="Attention Bridging Network for Knowledge Transfer">
<div> <strong>A Multi-Stage Refinement Network for Salient Object Detection</strong><br>    
Lihe Zhang, Jie Wu, <strong><u>Tiantian Wang</u></strong>, Pingping Zhang, Ali Borji, Huchuan Lu<br>
<strong>IEEE TIP</strong>, 2019
</div>
<div class="spanner"></div>
</div>
 -->
<!-- 
<div class="paper" id="AttnBN"><img class="paper" src="./pic/AttnBN.png" title="Attention Bridging Network for Knowledge Transfer">
<div> <strong>Edge-Aware Convolution Neural Network Based Salient Object Detection</strong><br>    
Wenlong Guan, <strong><u>Tiantian Wang</u></strong>, Jinqing Qi, Lihe Zhang, Huchuan Lu <br>
<strong>IEEE SPL</strong>, 2019
</div>
<div class="spanner"></div>
</div> -->



<!-- 
<div class="paper" id="AttnBN"><img class="paper" src="./pic/AttnBN.png" title="Attention Bridging Network for Knowledge Transfer">
<div> <strong>Deep Multi-Level Networks with Multi-Task Learning for Saliency Detection</strong><br>    
Lihe Zhang, Xiang Fang, Hongguang Bo, <strong><u>Tiantian Wang</u></strong>, Huchuan Lu <br>
<!-- <strong><u>Tiantian Wang</u></strong>, Lihe Zhang, Huchuan Lu, Chong Sun, Jinqing Qi <br> -->
<!-- <strong>Neurocomputing</strong>, 2019
</div>
<div class="spanner"></div>
</div> -->
 <!-- --> 

<!-- <div class="paper" id="AttnBN"><img class="paper" src="./pic/AttnBN.png" title="Attention Bridging Network for Knowledge Transfer">
<div> <strong>Multi-scale Pyramid Pooling Network for Salient Object Detection</strong><br>    
Dakhia Abdelhafid, <strong><u>Tiantian Wang</u></strong>, Huchuan Lu <br>
<strong>Neurocomputing</strong>, 2018
</div>
<div class="spanner"></div>
</div> -->


<!-- <div class="paper" id="AttnBN"><img class="paper" src="./pic/AttnBN.png" title="Attention Bridging Network for Knowledge Transfer">
<div> <strong>A Hybrid-Backward Renement Model for Salient Object Detection</strong><br>    
Dakhia Abdelhafid, <strong><u>Tiantian Wang</u></strong>, Huchuan Lu <br>
<strong>Neurocomputing</strong>, 2018
</div>
<div class="spanner"></div>
</div> -->






<!-- 

<div class="paper" id="GAIN"><img class="paper" src="./pic/GAIN.png" title="Tell Me Where to Look: Guided Attention Inference Network">
<div> <strong>Tell Me Where to Look: Guided Attention Inference Network</strong><br>
<strong><u>Kunpeng Li</u></strong>, Ziyan Wu, Kuan-Chuan Peng, Jan Ernst, Yun Fu <br>
IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2018 <strong>(Spotlight)</strong>
<a href='http://openaccess.thecvf.com/content_cvpr_2018/papers/Li_Tell_Me_Where_CVPR_2018_paper.pdf'>[PDF]</a>,
<a href='https://github.com/alokwhitewolf/Guided-Attention-Inference-Network'>[Code]</a> by <a href='https://github.com/alokwhitewolf'>alokwhitewolf</a>, 
<a href='https://www.youtube.com/watch?v=op9IBox_TTc'>[Talk]</a>, 
<a href='https://press.siemens.com/global/en/pressrelease/siemens-extends-sinumerik-edge-include-more-applications-bringing-artificial'>[Siemens Product]</a> 
</div>
<br>
<div> <strong>Guided Attention Inference Network</strong><br>
<strong><u>Kunpeng Li</u></strong>, Ziyan Wu, Kuan-Chuan Peng, Jan Ernst, Yun Fu <br>
IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), 2019
<a href='https://ieeexplore.ieee.org/abstract/document/8733010'>[Paper]</a>
</div>
<div class="spanner"></div>
</div>


<div class="paper" id="RCAN"><img class="paper" src="./pic/RCAN.png" title="Image Super-Resolution Using Very Deep Residual Channel Attention Networks">
<div> <strong>Image Super-Resolution Using Very Deep Residual Channel Attention Networks</strong><br>
Yulun Zhang, <strong><u>Kunpeng Li</u></strong>, Kai Li, Bineng Zhong, Yun Fu <br>
European Conference on Computer Vision (<strong>ECCV</strong>), 2018
<a href='https://arxiv.org/abs/1807.02758'>[PDF]</a>,
<a href='https://github.com/yulunzhang/RCAN'>[Code]</a>
</div>
<div class="spanner"></div>
</div>


<div class="paper" id="SN_reID"><img class="paper" src="./pic/SN_reID.png" title="Support Neighbor Loss for Person Re-Identification">
<div> <strong>Support Neighbor Loss for Person Re-Identification</strong><br>
Kai Li, Zhengming Ding, <strong><u>Kunpeng Li</u></strong>, Yulun Zhang, Yun Fu <br>
ACM Multimedia (<strong>ACM MM</strong>), 2018
<a href='https://arxiv.org/abs/1808.06030'>[PDF]</a>,
<a href='https://github.com/kailigo/SN_loss_for_reID'>[Code]</a>
</div>
<div class="spanner"></div>
</div>


<div class="paper" id="MDSLT"><img class="paper" src="./pic/MDSLT.png" title="Multi-stream Deep Similarity Learning Networks for Visual Tracking">
<div> <strong>Multi-stream Deep Similarity Learning Networks for Visual Tracking</strong><br>
<strong><u>Kunpeng Li</u></strong>, Yu Kong, Yun Fu <br>
International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>), 2017
<a href='https://www.ijcai.org/proceedings/2017/0301.pdf'>[PDF]</a>,
<a href='https://drive.google.com/file/d/1WoUK3G4khzI_qw1T48hvxa-7yPYYv3Ua/view'>[Benchmark Results]</a>,
<a href='https://www.youtube.com/watch?v=UgrwdRQYAIA'>[Video Results]</a>
</div>
<div class="spanner"></div>
</div>


<div class="paper" id="AirWriting"><img class="paper" src="./pic/AirWriting.png" title="A New Fingertip Detection and Tracking Algorithm and Its Application on Writing-in-the-air System">
<div> <strong>A New Fingertip Detection and Tracking Algorithm and Its Application on Writing-in-the-air System</strong><br>
<strong><u>Kunpeng Li</u></strong>, Xin Zhang <br>
IEEE International Conference on Image and Signal Processing, 2014
<a href='https://ieeexplore.ieee.org/abstract/document/7003824'>[PDF]</a>,
<a href='https://drive.google.com/file/d/0B6GPXWGb8uiyUW8tN2tmUERxWmc/view'>[Extension]</a>,
<a href='https://www.youtube.com/watch?v=gCHIq0OQwUM'>[Demo]</a>
</div>
<div class="spanner"></div>
</div>

 -->





<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Selected Awards</h2>
<div class="paper">
    <ul>
	<li> Excellent Postgraduate of Dalian City, 2018. </li>  
	<li> Excellent Graduate of Dalian University of Technology, 2015. </li>
  <!--     <li> Excellent Graduate Student, Wuhan University, 2015. </li>
    <li> Outstanding Undergraduate Thesis, Hubei Province, 2015. </li>	
    <li> Best Undergraduate Thesis, School of Remote Sensing and Information Engineering, Wuhan University, 2014. </li>
 -->    <!-- <li> Excellent Undergraduate Students, Wuhan University, 2012. </li> -->
    </ul>
</ul>
</div>
</div>
</div>

<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Professonal Activities</h2>
<div class="paper">
<ul>
<p><font size="5">
	<li> Reviewer for ECCV2020, CVPR2020, AAAI2020, WACV2020, ICCV2019</li>    	 	
	<li> Reviewer for TIP, TNNLS, PR, TMM</li>
    <!-- <li> Guest reviewer for AAAI 2017. </li>    	  -->
	<!-- <li >IEEE student member, AAAI student member. </li>    -->
</font></p>
</ul>
</div>
</div>
</div>



<!-- <div style="clear:both;">
<p align="right"><font size="5">Last Updated on 11th Dec, 2017</a></font></p>
<p align="right"><font size="5">Published with <a href='https://pages.github.com/'>GitHub Pages</a></font></p>
</div>
 -->
<!-- <hr> -->
<!-- <!--  -->
<!-- <div id="clustrmaps-widget"></div><script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?u=VWJ0&d=U3QgYTohL0BDKnd1NmsAJrR-Sr6wSsc3wxseuw4wyD4"></script> -->
<!-- -->
</body>
</html>
